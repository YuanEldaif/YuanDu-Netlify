<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.5.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Yuan Du">

  
  
  
    
  
  <meta name="description" content="Previously, decision theory was disscussed and an important part of is to evaluate a decision rule for decision making. Since the risk is the average loss \(L(\theta,d)\), different loss functions were used in Machine Learning models. Mean squared error (MSE) was mentioned as the most famous meausre by using squared error loss proposed by Gauss. Regression, Linear discriminant analysis (LDA) use squared error loss. The squared loss function tends to penalize outliers excessively, leading to slower convergence rates.">

  
  <link rel="alternate" hreflang="en-us" href="https://yuan-du.com/post/2020-12-13-loss-functions/decision-theory/">

  


  
  
  
  <meta name="theme-color" content="rgb(251, 191, 183)">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
    

    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Cutive+Mono%7CLora:400,700%7CRoboto:400,700&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.9985071f06fdf8e69922a7ae2061b748.css">

  

  




  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://yuan-du.com/post/2020-12-13-loss-functions/decision-theory/">

  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Yuan Du">
  <meta property="og:url" content="https://yuan-du.com/post/2020-12-13-loss-functions/decision-theory/">
  <meta property="og:title" content="Loss Functions in Machine Learning and LTR | Yuan Du">
  <meta property="og:description" content="Previously, decision theory was disscussed and an important part of is to evaluate a decision rule for decision making. Since the risk is the average loss \(L(\theta,d)\), different loss functions were used in Machine Learning models. Mean squared error (MSE) was mentioned as the most famous meausre by using squared error loss proposed by Gauss. Regression, Linear discriminant analysis (LDA) use squared error loss. The squared loss function tends to penalize outliers excessively, leading to slower convergence rates."><meta property="og:image" content="https://yuan-du.com/img/icon-192.png">
  <meta property="twitter:image" content="https://yuan-du.com/img/icon-192.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-12-13T22:27:29-04:00">
    
    <meta property="article:modified_time" content="2020-12-13T22:27:29-04:00">
  

  


    






  






<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yuan-du.com/post/2020-12-13-loss-functions/decision-theory/"
  },
  "headline": "Loss Functions in Machine Learning and LTR",
  
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "2020-12-13T22:27:29-04:00",
  
  "author": {
    "@type": "Person",
    "name": "Yuan Du"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Yuan Du",
    "logo": {
      "@type": "ImageObject",
      "url": "https://yuan-du.com/img/icon-512.png"
    }
  },
  "description": "Previously, decision theory was disscussed and an important part of is to evaluate a decision rule for decision making. Since the risk is the average loss \\(L(\\theta,d)\\), different loss functions were used in Machine Learning models. Mean squared error (MSE) was mentioned as the most famous meausre by using squared error loss proposed by Gauss. Regression, Linear discriminant analysis (LDA) use squared error loss. The squared loss function tends to penalize outliers excessively, leading to slower convergence rates."
}
</script>

  

  


  


  





  <title>Loss Functions in Machine Learning and LTR | Yuan Du</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Yuan Du</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Blog</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


  <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Loss Functions in Machine Learning and LTR</h1>

  

  
    



<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Dec 13, 2020
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    3 min read
  </span>
  

  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/categories/statistics/">Statistics</a>, <a href="/categories/machine-learning/">Machine Learning</a>, <a href="/categories/data-science/">Data Science</a>, <a href="/categories/deep-learning/">Deep Learning</a></span>
  

  
    
<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://yuan-du.com/post/2020-12-13-loss-functions/decision-theory/&amp;text=Loss%20Functions%20in%20Machine%20Learning%20and%20LTR" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://yuan-du.com/post/2020-12-13-loss-functions/decision-theory/&amp;t=Loss%20Functions%20in%20Machine%20Learning%20and%20LTR" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook-f"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Loss%20Functions%20in%20Machine%20Learning%20and%20LTR&amp;body=https://yuan-du.com/post/2020-12-13-loss-functions/decision-theory/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://yuan-du.com/post/2020-12-13-loss-functions/decision-theory/&amp;title=Loss%20Functions%20in%20Machine%20Learning%20and%20LTR" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Loss%20Functions%20in%20Machine%20Learning%20and%20LTR%20https://yuan-du.com/post/2020-12-13-loss-functions/decision-theory/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://yuan-du.com/post/2020-12-13-loss-functions/decision-theory/&amp;title=Loss%20Functions%20in%20Machine%20Learning%20and%20LTR" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>


  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style">
      
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<p>Previously, <a href="https://yuan-du.com/post/2020-09-23-decision-theory/decision-theory/">decision theory</a> was disscussed and an important part of is to evaluate a decision rule for decision making. Since the risk is the average <strong>loss <span class="math inline">\(L(\theta,d)\)</span></strong>, different loss functions were used in Machine Learning models. Mean squared error (MSE) was mentioned as the most famous meausre by using squared error loss proposed by Gauss. Regression, Linear discriminant analysis (<a href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis">LDA</a>) use squared error loss. The squared loss function tends to penalize outliers excessively, leading to slower convergence rates. There are other popular loss functions and they are applied in various Machine Learning and Deep Learning models. The plot shows the loss function for two class classification.</p>
<div class="figure">
<img src="/img/Hinge_expo_log.jpg" alt="Loss Functions: &quot;Loss vs y*f(x); y= \pm 1, the prediction is f, with class prediction sign(f)&quot;" />
<p class="caption">Loss Functions: "Loss vs y*f(x); <span class="math inline">\(y= \pm 1\)</span>, the prediction is f, with class prediction sign(f)"</p>
</div>
<p><strong>1. <span style="color:green">Hinge loss</span></strong></p>
<p>The hinge loss is a loss function used for “maximum-margin” classification, most notably for support vector machine (SVM).It’s equivalent to minimize the loss function <span class="math inline">\(L(y,f) = [1-yf]_+\)</span>.</p>
<p>With <span class="math inline">\(f(x) = h(x)^T \beta + \beta_0\)</span>, the optimization problem is loss + penalty:
<span class="math display">\[ \min_{\beta_0,\beta} \sum_{n=1}^{\infty}[1-y_if(x_i)]_+ + \frac{\lambda}{2}||\beta||^2 \]</span></p>
<p><strong>2. <span style="color:DeepSkyBlue">Exponential loss</span></strong></p>
<p>The exponential loss is convex and grows exponentially for negative values which makes it more sensitive to outliers. The exponential loss is used in the <a href="https://en.wikipedia.org/wiki/AdaBoost">AdaBoost algorithm</a>. The principal attraction of exponential loss in the context of additive modeling is computational. The additive expansion produced by AdaBoost is estimating onehalf of the log-odds of P(Y = 1|x). This justifies using its sign as the classification rule.</p>
<p>The population minimizer is:
<span class="math display">\[f^*(x) = \arg\min_{f(x)} E_{Y|x}(e^{-Yf(x)}) = \frac{1}{2} log\frac{Pr(Y = 1|x)}{Pr(Y = -1|x)}\]</span>
or
<span class="math display">\[Pr(Y = 1|x) = \frac{1}{1+e^{-2f*(x)}}\]</span>
<strong>3. <span style="color:Gold">Logistic loss(Binomial Deviance)</span></strong></p>
<p>The logistic loss is also called as binomial log-likelihood loss or cross entropy loss. It’s used for logistic regression and in the <a href="https://en.wikipedia.org/wiki/LogitBoost">LogitBoost algorithm</a>. The cross entropy loss is ubiquitous in <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks/Deep Learning</a>.</p>
<p>The binomial log-likelihood loss function is:
<span class="math display">\[l(Y,p(x)) = Y&#39;logp(x) + (1-Y&#39;)log(1-p(x))\]</span></p>
<p>or the deviance
<span class="math display">\[-l(Y,f(x) = log(1+e^{-2Yf(x)})\]</span></p>
<p><strong>Summary Table</strong></p>
<table>
<colgroup>
<col width="11%" />
<col width="28%" />
<col width="37%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Loss Function</th>
<th align="center"><span class="math inline">\(L[y,f(x)]\)</span></th>
<th align="center">Minimizing Function</th>
<th align="left">Advantage/Disadvantage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Squared loss</td>
<td align="center"><span class="math inline">\([y-f(x)] = [1-yf(x)]^2\)</span></td>
<td align="center"><span class="math inline">\(2Pr(Y=+1|x)-1\)</span></td>
<td align="left">easy cross validation of regularization parameters/slower convergence rates</td>
</tr>
<tr class="even">
<td align="left">Hinge loss</td>
<td align="center"><span class="math inline">\([1-yf]_+\)</span></td>
<td align="center"><span class="math inline">\(sign[Pr(Y=+1|x)-\frac{1}{2}]\)</span></td>
<td align="left">support points/not differentiable at<span class="math inline">\(yf(x)=1\)</span></td>
</tr>
<tr class="odd">
<td align="left">Exponential loss</td>
<td align="center"><span class="math inline">\(\frac {1}{2} log(1+e^{-Yf(x)})\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{2}log\frac{Pr(Y =+1|x)}{Pr(Y =-1|x)}\)</span></td>
<td align="left">grows exponentially for negative values,more sensitive to outliers</td>
</tr>
<tr class="even">
<td align="left">Logistic loss</td>
<td align="center"><span class="math inline">\(log(1+e^{-Yf(x)})\)</span></td>
<td align="center"><span class="math inline">\(log\frac{Pr(Y =+1|x)}{Pr(Y =-1|x)}\)</span></td>
<td align="left">grows linearly for negative values,less sensitive to outliers</td>
</tr>
</tbody>
</table>
<p><strong>Similarities between loss functions: </strong></p>
<ul>
<li><p>Hinge loss, Exponential loss, Logistic loss have very similar tails, giving zero penalty to points well inside their margin and linear or exponential penalty to points on the wrong side adn far away. <span style="color:FireBrick">Squared error loss</span> gives a quadratic penalty and points inside their own margin have a strong influence on othe model as well.</p></li>
<li><p>Exponential loss and Logistic loss have the same asymptotes as the SVM hinge loss but are rounded in the interrior.</p></li>
</ul>
<p><br />
The above popular loss functions are also used in deep learning, for example, Learing To Rank (<a href="https://en.wikipedia.org/wiki/Learning_to_rank">LTR</a>) for a Recommender System (<a href="https://en.wikipedia.org/wiki/Recommender_system">RS</a>). Differently from traditional machine learning problem that’s to predict the target either classification or regression, LTR optimizes the ranking accruacy instead of the prediction probability accuracy.</p>
<p>Ranking is useful in our daily life for Recommendation system like Netflix, Amazon; Information Retrieval like goole; Drug discovery; Bioinformatics. Generally speaking, there are three types of rankings: <em>bipartie ranking, k-partite ranking, real-valued labels based ranking</em>. <code>RankSVM, RankBoost, RankNet</code> with corresponding loss functions are used for the ranking problems. A seperate post will be written to further demonstrate LTR framework and how the loss functions are used.</p>
<p><br />
<br />
<em>Reference:</em></p>
<p><em>Hastie, T., Tibshirani, R., &amp; Friedman, J. H. (2009). The elements of statistical learning: data mining, inference, and prediction. 2nd ed. New York: Springer.</em>
<em>Computer Science &amp; Artificial Intelligence Laboratory, MIT</em></p>

    </div>

    


    

<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/machine-learning/">Machine Learning</a>
  
  <a class="badge badge-light" href="/tags/data-science/">Data Science</a>
  
  <a class="badge badge-light" href="/tags/decision-theory/">Decision Theory</a>
  
  <a class="badge badge-light" href="/tags/ltr/">LTR</a>
  
  <a class="badge badge-light" href="/tags/deep-learning/">Deep Learning</a>
  
</div>



    
      








  






  
  
  
    
  
  
  <div class="media author-card">
    
      
      <img class="portrait mr-3" src="/authors/admin/avatar_hu256edfcb7e5017748129576372c78297_1464515_250x250_fill_q90_lanczos_center.jpg" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://yuan-du.com/">Yuan Du</a></h5>
      <h6 class="card-subtitle">Statistician / Data Scientist</h6>
      <p class="card-text">My interests include applied Statitics, ML/DL and Healthcare.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?view_op=list_works&amp;hl=en&amp;user=WXROPRYAAAAJ" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/YuanEldaif" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/yuaneldaif/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>



      
      
      <div class="article-widget">
        <div class="hr-light"></div>
        <h3>Related</h3>
        <ul>
          
          <li><a href="/post/2021-06-07-ltr/decision-theory/">Learning To Rank (LTR)</a></li>
          
          <li><a href="/post/2020-09-23-decision-theory/decision-theory/">Game Theory and Decision Theory</a></li>
          
          <li><a href="/post/2020-07-30-statvsml/statisticsvsml/">Research Experience - Comparing Statistics vs Machine Learning</a></li>
          
          <li><a href="/project/kaggle-project/">Kaggle Instant Gratification Competition Project</a></li>
          
          <li><a href="/post/2020-04-18-bayesian-analysis/bayesian-analysis/">Bayesian Analysis</a></li>
          
        </ul>
      </div>
      
    

    

    


  </div>
</article>

      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js" integrity="sha256-0w92bcB21IY5+rGI84MGj52jNfHNbXVeQLrZ0CGdjNY=" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
      
    
    
    
    <script src="/js/academic.min.178b0ffae270403f2b091a5e05e58078.js"></script>

    <footer class="site-footer">

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=e3c1e2&w=300&t=n&d=39cx_8ONS0zJNxZU-HLY3ZlBYR_a6imIeSGMWjKD4us&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>

</footer>



  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    &copy; Yuan Du, 2021 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
