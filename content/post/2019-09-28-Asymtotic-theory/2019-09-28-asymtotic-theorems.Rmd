---
title: Important asymptotic theorems
author: Yuan Du
date: '2019-09-28'
categories: 
  - Statistics

#lastmod: '2019-09-28T10:57:42-04:00'
slug: important-asymtotic-theorems
subtitle: ''
summary: ''
tags: 
  - Asymptotic Theory
  - Theorem
authors: []
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
---
Machine learning algorithms are very populuar. Even in database design, all of those indexes remain general purpose data structures; they assume nothing about the data distribution and do not take advantage of more common patterns prevalent in real world data. Knowing the exact data distribution enables highly optimizing almost any index structure. A [learned indexe structures](https://arxiv.org/pdf/1712.01208.pdf) was proposed in 2018 to take advantages of learning a model that reflects the patterns in the data and thus to enable the automatic synthesis of specialized index structures.

However, machine learing algorithms not stable/consistant on the performance because lots of them are not using statistical inference. Thus, statistical theory for estimating function which has established hundreds of years ago becomes a more and more interesting research direction. 

In this blog, I will introduce a few important asymptotic theorems that are fundamental to prove some machine learning algorithms, such as SVM and Markov Chain.

**Fatou-Lebesgue Lemma**:
if the random variable $X_n \xrightarrow{a.s} X$ and if for all n $X_n \geq Y$ with $E|Y| < \infty$, then
$$E(\liminf_{n \to \infty} X_n) \leq \liminf_{n \to \infty} E(X_n)$$ 
It holds if $X_n \geq 0$ for all n. 

By using `Fatou-Lebesgue Lemma`, we can prove the `(a) Monotone convergence Theorem`, and the `(b) Lebesgue Dominated Convergence Theorem`.

   - **(a) Monotone convergence Theorem**: If $X_n$ is a sequence of nonnegative measurable functions denoted by $0 \leq x_1 \leq x_2 \dots \leq x_n \leq x_{n+1}$ and $X_n \xrightarrow{a.s} X$, then $\lim_{0\to\infty}E(X_n)=E(\lim_{0\to\infty}X_n) = EX$

   - **(b) Lebesgue Dominated Convergence Theorem**：If the random variables $X_n \to X$, then we have $|X_n| \leq Y$, almost surely for all n. Then $X_n \in L^1$, $X \in L^1$, and $\lim_{0\to\infty}E(X_n) = E(X)$.
     
     **SVM** could be an application of `Lebesgue Dominated Convergence Theorem`. We can use the theorem to prove the hinge loss function, when the data is not linearly separable. In a sufficiently rich hypothesis space—or equivalently, for an appropriately chosen kernel—the SVM classifier will converge to the simplest function (in terms of $R$) that correctly classifies the data. This extends the geometric interpretation of SVM—for linear classification, the empirical risk is minimized by any function whose margins lie between the support vectors, and the simplest of these is the max-margin classifier.
  
**Borel-Cantelli Lemma**: for \{$A_n: n \geq 1$\} a sequence of events in a probability space if $\sum_{n=1}^{\infty}P(A_n) < \infty$ then $P(A_n i.o.)=0$; only a finite number of the events occur, with probability 1. Conversely, if the $A_n$ are independent and $\sum_{n=1}^{\infty}P(A_n) = \infty$, then $P(A_n i.o.)=1$; an infinite number of the events occur, with probability 1.

`Borel-Cantelli Lemma` is useful in problems related to the a.s. convergence. It could be written as $P(|X_n - X|>\epsilon i.o.) = 0, \forall \epsilon > 0$. 

The **Markov chain**^[A **Markov chain** is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. In probability theory and related fields, a Markov process, named after the Russian mathematician [Andrey Markov](https://en.wikipedia.org/wiki/Andrey_Markov), is a [stochastic process](https://en.wikipedia.org/wiki/Stochastic_process) that satisfies the [Markov property](https://en.wikipedia.org/wiki/Markov_property).  The defining characteristic of a Markov chain is that no matter how the process arrived at its present state, the possible future states are fixed. In other words, the probability of transitioning to any particular state is dependent solely on the current state and time elapsed. The **state space**, or set of all possible states, can be anything: letters, numbers, weather conditions, baseball scores, or stock performances.] can be proved by using `Borel-Cantelli Lemma`. The probability of having state from $i$ and eventually return to $i$ is 1. If this probability is strictly less than 1, $i$ is called transient.


