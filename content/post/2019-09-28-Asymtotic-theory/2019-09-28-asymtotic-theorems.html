---
title: Important asymptotic theorems
author: Yuan Du
date: '2019-09-28'
categories: 
  - Statistics

#lastmod: '2019-09-28T10:57:42-04:00'
slug: important-asymtotic-theorems
subtitle: ''
summary: ''
tags: 
  - Asymptotic Theory
  - Theorem
authors: []
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
---



<p>Machine learning algorithms are very populuar. Even in database design, all of those indexes remain general purpose data structures; they assume nothing about the data distribution and do not take advantage of more common patterns prevalent in real world data. Knowing the exact data distribution enables highly optimizing almost any index structure. A <a href="https://arxiv.org/pdf/1712.01208.pdf">learned index structures</a> was proposed in 2018 to take advantages of learning a model that reflects the patterns in the data and thus to enable the automatic synthesis of specialized index structures.</p>
<p>However, machine learing algorithms not stable/consistant on the performance because lots of them are not using statistical inference. Thus, statistical theory for estimating function which has established hundreds of years ago becomes a more and more interesting research direction.</p>
<p>In this blog, I will introduce a few important asymptotic theorems that are fundamental to prove some machine learning algorithms, such as SVM and Markov Chain.</p>
<p><strong>Fatou-Lebesgue Lemma</strong>:
if the random variable <span class="math inline">\(X_n \xrightarrow{a.s} X\)</span> and if for all n <span class="math inline">\(X_n \geq Y\)</span> with <span class="math inline">\(E|Y| &lt; \infty\)</span>, then
<span class="math display">\[E(\liminf_{n \to \infty} X_n) \leq \liminf_{n \to \infty} E(X_n)\]</span>
It holds if <span class="math inline">\(X_n \geq 0\)</span> for all n. </p>
<p>By using <code>Fatou-Lebesgue Lemma</code>, we can prove the <code>(a) Monotone convergence Theorem</code>, and the <code>(b) Lebesgue Dominated Convergence Theorem</code>.</p>
<ul>
<li><p><strong>(a) Monotone convergence Theorem</strong>: If <span class="math inline">\(X_n\)</span> is a sequence of nonnegative measurable functions denoted by <span class="math inline">\(0 \leq x_1 \leq x_2 \dots \leq x_n \leq x_{n+1}\)</span> and <span class="math inline">\(X_n \xrightarrow{a.s} X\)</span>, then <span class="math inline">\(\lim_{0\to\infty}E(X_n)=E(\lim_{0\to\infty}X_n) = EX\)</span></p></li>
<li><p><strong>(b) Lebesgue Dominated Convergence Theorem</strong>：If the random variables <span class="math inline">\(X_n \to X\)</span>, then we have <span class="math inline">\(|X_n| \leq Y\)</span>, almost surely for all n. Then <span class="math inline">\(X_n \in L^1\)</span>, <span class="math inline">\(X \in L^1\)</span>, and <span class="math inline">\(\lim_{0\to\infty}E(X_n) = E(X)\)</span>.</p></li>
</ul>
<p><strong>Partical converge relation</strong>：<span class="math inline">\(X_n \xrightarrow{P}X\)</span> if and only if every subsequence <span class="math inline">\(n_1, N_2, \dots \epsilon \{1,2,\dots\}\)</span> has a sub-sequence <span class="math inline">\(m_1, m_2, \dots \epsilon \{n_1,n_2,\dots \}\)</span> such that <span class="math inline">\(X_{m_j} \xrightarrow{a.s}X\)</span> as <span class="math inline">\(j\to\infty\)</span>.</p>
<p><strong>Borel-Cantelli Lemma</strong>: for {<span class="math inline">\(A_n: n \geq 1\)</span>} a sequence of events in a probability space if <span class="math inline">\(\sum_{n=1}^{\infty}P(A_n) &lt; \infty\)</span> then <span class="math inline">\(P(A_n i.o.)=0\)</span>; only a finite number of the events occur, with probability 1. Conversely, if the <span class="math inline">\(A_n\)</span> are independent and <span class="math inline">\(\sum_{n=1}^{\infty}P(A_n) = \infty\)</span>, then <span class="math inline">\(P(A_n i.o.)=1\)</span>; an infinite number of the events occur, with probability 1.</p>
<p><code>Borel-Cantelli Lemma</code> is useful in problems related to the a.s. convergence. It could be written as <span class="math inline">\(P(|X_n - X|&gt;\epsilon i.o.) = 0, \forall \epsilon &gt; 0\)</span>.</p>
<p><strong>SVM</strong><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>could be an application of <code>Lebesgue Dominated Convergence Theorem</code>. We can use the theorem and <code>Partical converge relation</code> to prove the hinge loss function, when the data is not linearly separable. By limiting on Hilbert space, a weakly convergent subsequence. We can apply asymptotic normality property on the regularization parameter <span class="math inline">\(\lambda_i \to 0\)</span> and thus to solve the miminization problem on the hyperplane <span class="math inline">\(\omega_n\)</span>, where the solution <span class="math inline">\(\tilde{\omega}= \omega_*\)</span> because <span class="math inline">\(\omega_*(\lambda_i) \xrightarrow{a.s.} \omega_*\)</span>).</p>
<p>The <strong>Markov chain</strong><a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> can be proved by using <code>Borel-Cantelli Lemma</code>. The probability of having state from <span class="math inline">\(i\)</span> and eventually return to <span class="math inline">\(i\)</span> is 1. If this probability is strictly less than 1, <span class="math inline">\(i\)</span> is called transient.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><strong>SVM</strong> is supervised learning model with associated learning algorithm that analyzes data used for classification and regression analysis.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>A <strong>Markov chain</strong> is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. In probability theory and related fields, a Markov process, named after the Russian mathematician <a href="https://en.wikipedia.org/wiki/Andrey_Markov">Andrey Markov</a>, is a <a href="https://en.wikipedia.org/wiki/Stochastic_process">stochastic process</a> that satisfies the <a href="https://en.wikipedia.org/wiki/Markov_property">Markov property</a>. The defining characteristic of a Markov chain is that no matter how the process arrived at its present state, the possible future states are fixed. In other words, the probability of transitioning to any particular state is dependent solely on the current state and time elapsed. The <strong>state space</strong>, or set of all possible states, can be anything: letters, numbers, weather conditions, sales volume，etc.<a href="#fnref2" class="footnote-back">↩</a></p></li>
</ol>
</div>
