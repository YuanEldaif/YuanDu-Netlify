---
title: Bayesian Analysis
author: Yuan Du
date: '2020-04-18'
slug: bayesian-analysis
categories:
  - Statistics
  - R
tags:
  - Bayesian
  - Statistical Modeling
  - Machine Learning
  - MCMC
subtitle: ''
summary: ''
authors: []
lastmod: '2020-04-18T22:27:29-04:00'
featured: no
image:
  caption: yes
  focal_point: ''
  preview_only: no
projects: []
---



<p>Bayesian approach becomes more and more popular because of the improvement of mordern computing ability for machine learning and big data. Bayesian analysis is a completely different approach compared to frequentist approach. Yet, it’s more challenging. To be able to understand and learn the Bayesian approch, <code>first</code>, we will need to have knowledge of conditional probability. <code>Second</code>, to have knowledge of different distributions such as normal, bernoulli, binomial, gamma, beta, cauchy,possion, etc. <code>Third</code>, to be familar with calculus. We need to calculate derivatives and integration of different distributions. <code>Last but not at least</code>, to be familar with simulation sampling technique such as Grid sampling, Variational Bayes and Monte Carlo Markov Chian (MCMC) including popular Gibbs sampling, Metropolis Hastings Sampling, Hamiltonian Monte Carlo(HMC)，etc. Luckily, there are a few software tools <a href="https://web.sgh.waw.pl/~atoroj/ekonometria_bayesowska/jags_user_manual.pdf">Jags</a>, <a href="https://mc-stan.org/users/documentation/">Stan</a> .etc can be used for Gibbs sampling and HMC.
<img src="/img/Human.jpg" alt="‘Credit: https://www2.isye.gatech.edu/~brani/isyebayes/jokes.html’" /></p>
<p>The concept is simple. According to Bayes Theorem <span class="math inline">\(p(\theta|y) = \frac{p(y|\theta)p(\theta)}{p(y)}\)</span> or without normalization <span class="math inline">\(p(\theta|y) \sim p(y|\theta)p(\theta)\)</span>, we want to gain the posterior distribution by using prior information and likelihood of the data information. Most of the time, we use log likelihood instead for easier calculation since <span class="math inline">\(log( a*b )= loga +logb\)</span>. Bayesian approach involves much more math than frequentist approach and more complicated. Frequentist focus on one point (hypothesis), and bayesian focuses on a looking forward range.
<img src="/img/FreBay.png" alt="Credit: https://365datascience.com/bayesian-vs-frequentist-approach/" /></p>
<p>(To be continued…)</p>
