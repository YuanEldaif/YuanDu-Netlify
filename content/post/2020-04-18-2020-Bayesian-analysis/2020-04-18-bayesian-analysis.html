---
title: Bayesian Analysis
author: Yuan Du
date: '2020-04-18'
slug: bayesian-analysis
categories:
  - Statistics
  - R
tags:
  - Bayesian
  - Statistical Modeling
  - Machine Learning
  - MCMC
subtitle: ''
summary: ''
authors: []
lastmod: '2020-04-18T22:27:29-04:00'
featured: no
image:
  caption: yes
  focal_point: ''
  preview_only: no
projects: []
---



<p>Bayesian approach becomes more and more popular because of the improvement of mordern computing ability for machine learning and big data. Bayesian analysis is a completely different approach compared to frequentist approach. Yet, it’s more challenging. To be able to understand and learn the Bayesian approch, <code>first</code>, we will need to have knowledge of conditional probability. <code>Second</code>, to have knowledge of different distributions such as normal, bernoulli, binomial, gamma, beta, cauchy,possion, etc. <code>Third</code>, to be familar with calculus. We need to calculate derivatives and integration of different distributions. <code>Last but not at least</code>, to be familar with simulation sampling technique such as Grid sampling, Variational Bayes and Monte Carlo Markov Chian (MCMC) including popular Gibbs sampling, Metropolis Hastings Sampling, Hamiltonian Monte Carlo(HMC),etc. Luckily, there are a few software tools <a href="https://web.sgh.waw.pl/~atoroj/ekonometria_bayesowska/jags_user_manual.pdf">Jags</a>, <a href="https://mc-stan.org/users/documentation/">Stan</a> .etc can be used for Gibbs sampling and HMC.
<img src="/img/Human.jpg" alt="‘Credit: https://www2.isye.gatech.edu/~brani/isyebayes/jokes.html’" /></p>
<p>The concept is simple. According to Bayes Theorem <span class="math inline">\(p(\theta|y) = \frac{p(y|\theta)p(\theta)}{p(y)}\)</span> or without normalization <span class="math inline">\(p(\theta|y) \sim p(y|\theta)p(\theta)\)</span>, we want to gain the posterior distribution by using prior information and likelihood of the data information. Most of the time, we use log likelihood instead for easier calculation since <span class="math inline">\(log( a*b )= loga +logb\)</span>. Bayesian approach involves much more math than frequentist approach and more complicated. Frequentist focus on one point (hypothesis), and bayesian focuses on a looking forward range.
<img src="/img/FreBay.png" alt="Credit: https://365datascience.com/bayesian-vs-frequentist-approach/" /></p>
<p><strong>If friquentist and bayesian approach are just two different ways to look into things, Why and when is recommended to use Bayesian approach instead of frequentist approach?</strong></p>
<p>Here are a few examples to use Bayesian approach over frequentist approach:</p>
<ul>
<li><p>Clear prior information: the example in the book <a href="http://www.stat.columbia.edu/~gelman/book/BDA3.pdf">BD3</a> of Andrew Gelman’s in Chapter 1, problem 6. The prior information is that approximately 1/125 of all births are fraternal twins and 1/300 of births are identical twins.</p></li>
<li><p>Seperation problems. For example logistic regression couldn’t converge due to high dimension and small sample size.</p></li>
<li><p>Estimate multiple outcomes with credible interval. For example, family doctors try to diagnosis diseases (such as cold, flu) based on multiple symptoms (such as headache, sore throat, high temprature) and the probabilities of all symptoms sum up to limited possible diseases.</p></li>
<li><p>Small sample size with multiple experiments and limited budget.It’s a preferred meta analysis than tranditional meta analysis that has high heterogeneity with different recources since it provides a credible interval instead of confident interval.</p></li>
</ul>
<p>(To be continued…)</p>
